
\documentclass[preprint,authoryear]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{lipsum}
\usepackage{amsmath}
\usepackage{proof}

\def\turn{\vdash}
\def\conv{\approx}

\newcommand{\fun}[1]{\textmd{#1}}
\newcommand{\cir}[1]{\textcircled{\raisebox{-0.9pt}{#1}}}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{20yy} 
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

\titlebanner{DRAFT}        % These are ignored unless
%% \preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Expressionless Weak-Head Normal Forms}
%% \subtitle{Subtitle Text, if any}

\authorinfo{Larry Diehl}
           {Portland State University}
           {ldiehl@cs.pdx.edu}

\authorinfo{Tim Sheard}
           {Portland State University}
           {sheard@cs.pdx.edu}

\maketitle

\begin{abstract}
\lipsum[2-3]
\end{abstract}

\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore, 
% you may leave them out
\terms
term1, term2

\keywords
keyword1, keyword2

\section{Introduction}

The text of the paper begins here.

Lots of text.

More text.

Lots of text.

More text.


Lots of text.

More text.

Lots of text.

More text.

\section{Dependent Type Checking}

The motivation for weak-head normal forms in dependent type theory is
to strike a balance between simplicity and efficiency in the
implementation of the type checker. 

\subsection{Specification}

Before considering the {\it implementation} of a dependent type checker,
let's consider the complexities that arise in the
{\it specification} of dependent typing rules.
The rule for dependent application exposes the complexities
that arise in dependent type checking.

$$
\infer[]
  {\Gamma \turn f~a : B[a]}
{
  \Gamma \turn f : \Pi~A~B
  &
  \Gamma \turn a : A
}
$$

There are 3 interesting
constraints in this rule, and all of them have to do with what is
happening in the {\it type} position of the typing judgement.

\begin{enumerate}
\item The type of the function $f$ must be $\Pi~A~B$, thus it must at
  least be in head-normal form.
\item The type of $a$ must be equal to the domain of $f$.
\item The type of the application $f a$ is the substitution of $a$ for
  the bound variable in $B$.
\end{enumerate}

Because redexes can appear in dependent types, it is sometimes
necessary for types to be reduced before a typing rule becomes valid.
Otherwise, the following 3 problems can violate the aforementioned
constraints.

\begin{enumerate}
\item The type of $f$ is a redex like $(\lambda x. x)~(\Pi~A~B)$.
\item The type of $a$ is $A$, while the codomain of $f$ is a redex like
$(\lambda x. x)~A$.
\item Substituting the term $a$ into $B$ can create a redex, resulting
  in problems 1 and 2 somewhere else in type checking.
\end{enumerate}

The specification of typing rules can sweep all of these
problems under the rug by via a conversion rule.

$$
\infer[]
  {\Gamma \turn a : B}
{
  \Gamma \turn a : A
  &
  A \conv B
}
$$

The conversion relation $\conv$ considers types to equal after
reducing redexes. Hence, $\conv$ at least implements $\alpha$-$\beta$
equality, but it may implement additional forms of equality like $\eta$.

\subsection{Implementation}

Dependent type theory can be specified succinctly because the
conversion relation is nondeterministic. In contrast, an
implementation of a dependent type checker in a functional language
must be deterministic. Additionally, the implementation must be
reasonably efficient to execute. 

Below we consider 4 different Haskell implementations of type checking
function application. The 4 implementations differ in the syntactic
grammar used for types: First expressions, then normal forms, then
weak-head normal forms with expression closures, and finally our novel
weak-head normal forms with expressionless closures.

\paragraph{Expression Types}

Consider the function case of a type checker for expressions below.
For simplicity, we assume that all terms are annotated enough for us
to infer types instead of checking them. Additionally, the terms are
in de Bruijn notation so we do not need to deal with $\alpha$-renaming.
The input of \texttt{infer} is an expression
value, and the output is an expression type in a type checking monad.

\begin{verbatim}
infer :: Exp -> TCM Exp
infer (App f a) = do
  Pi _A _B <- infer f
  _A'      <- infer a
  unless (_A == _A') $
    throwError "Domain not convertible to argument"
  return . norm (B `sub` a)
\end{verbatim}

Whether or not the code above is correct depends on the rest of the
implementation of \texttt{infer}, what the conversion function
\texttt{(==)} does, and what the normalization function
\texttt{norm} does. Because the grammar of expressions is so flexible,
we can never be sure if a given expression is in normal form,
weak-head normal form, or if the head position is a redex.

The easiest way to get the implementation correct is to make
\texttt{norm} compute to full normal form. This way,
conversion \texttt{(==)} can be a simple syntactic equality. The
(albeit more complex) implementation makes \texttt{norm} compute only
to weak-head normal form, and conversion \texttt{(==)} first check
syntactic equality, and then compute away redexes if syntactic
equality fails. Whatever normal form we compute to, we need to make
sure that all cases of \texttt{infer} do it so that we can
successfully match against \texttt{Pi \_A \_B}.

Why is it a good idea to prefer weak-head normal forms over normal
forms? The normal forms can get quite large! Consider type checking
the application case where both the type of the argument (\texttt{\_A'})
and the domain (\texttt{\_A}) are the finite set type
\texttt{Fin (2 ** 1024)}. Computing both of these types to normal form
and before comparing them is not practical, while comparing the
terms with the redexes still present is reasonable.

\paragraph{Normal Form Types}

As mentioned above, computing to full normal form is not practical for
implementing a dependent type checker. Nevertheless, let us consider
the advantages obtained by having grammatically enforced normal form
types.

Below is an \texttt{infer} function that takes in an expression
and produces a type in normal form. The conversion function
\texttt{(==)} is just syntactic equality, and definition looks like
the expression version, except for the last line. In the expression
version we first syntactially substitute the argument \texttt{a} into
the codomain \texttt{B}, and then normalize the result. However,
syntactic substitution can create a redex, so it is not a well-formed
operation on normal forms. Instead, we first normalize the argument,
and then hereditarily substitute~\cite{TODO} into the codomain, which
computes away any redex created while substituting.

\begin{verbatim}
infer :: Exp -> TCM Nf
infer (App f a) = do
  Pi _A _B <- infer f
  _A'      <- infer a
  unless (_A == _A') $
    throwError "Domain not equal to argument"
  a' <- norm a
  return (B `hsub` a')
\end{verbatim}

There are three major benefits we get by having grammatically enforced
normal forms types. The first two advantages have to do with
simplicity in the implementation, and allows us to have a type checker
with a minimal number of cases.

\begin{enumerate}
\item Because the type signature of \texttt{infer} enforces that it
  returns a normal form, our pattern match against \texttt{Pi \_A \_B}
  always works (we can't forget to compute to normal form in some case
  of \texttt{infer}).
\item The conversion function of \texttt{(==)} can be a simple
  equality check, which can even be derived by Haskell.
\item The grammar of expressions and normal forms are defined
  independently, which can be exploited to implement a very small type
  checker!
\end{enumerate}

The last benefit of normal form types, which we call the
 {\it independence} property, needs more explaining. Think of
the expressions as a minimal surface language, and the
normal forms as a core language. The only expression constructors that we
need are variables, functions, and applications. Normal forms have the
same constructors, but also constructors for the types, introduction,
and elimination rules of all non-function types in the languages (e.g.
booleans, natural numbers, lists, trees, products, sums, etc).

\begin{verbatim}
data Exp = Var Int | Lam (Bind Exp) | App Exp Exp

data Nf = Type | Nat | Pi Nf (Bind Nf)
  | Zero | Suc Nf | Lam (Bind Nf) | Ne Ne

data Ne = Var Int | App Ne Nf
  | ElimNat (Bind Nf) Nf (Bind2 Nf) Ne
\end{verbatim}

How is it possible to have such a small expression grammar? Type
formers, constructors, and eliminators for all other types can be
exposed as definitions in an initial environment. If a normal form
primitive has multiple arguments, it can be wrapped with lambdas. This
means that a primitive like \texttt{Suc} is exposed as a variable
whose type is \texttt{Nat => Nat}, so users can even partially apply
them instead of needing to use the fully-applied primitives. 

\begin{verbatim}
zeroT = Nat
zero = Zero

sucT = Nat :=> Nat
suc = Lam (Bind (Suc (Var 0)))

elimNatT = Pi (Nat :=> Type)
  (Bind (Nat
     :=> Pi Nat (Bind (App (Var 1) (Var 0)
            :=> App (Var 1) (Suc (Var 0))))
     :=> Pi Nat (Bind (App (Var 1) (Var 0)))
  ))
elimNat = Lam (Bind (Lam (Bind (Lam (Bind
  ElimNat
    (Bind (Var 1 `App` Var 0))
    (Var 1)
    (Bind2 (Var 4 `App` Var 0 `App` Var 1))
    (Var 3)
  )))))

initCtx = [zeroT, sucT, elimNatT]
initEnv = [zero, suc, elimNat]
\end{verbatim}

The initial context \texttt{initCtx} contains types for all
non-$\Pi$ primitive constructions, and is used by \texttt{infer} in the
variable case.
The initial environment \texttt{initEnv} contains values for all
non-$\Pi$ primitive constructions, and is used by \texttt{norm} in the
variable case.

So what have we achieved by using this technique of embedding primitives
in an initial context and environment? Now our type checker
(\texttt{infer}) and our normalizer (\texttt{norm}) only need to
handle 3 cases, one for each constructor in the expression grammar!
This is quite nice, as a dependent type checker gets complicated
quickly as you add new feature. For example, if we added
Matita-style~\cite{TODO} elaboration of implicit arguments to
metavariables and unification problems, we would only need to
implement it for 3 cases of our \texttt{Exp} grammar.
Furthermore, changes to our primitives no longer require changes to
the type checker.

\paragraph{WHNF Types with Expressions}

So far we have seen a dependent type checker that uses
expression types, which may be done efficiently or inefficiently but
has no grammatical correctness properties, and a checker that uses
normal form types, which is inefficient but has grammatically enforced
correctness properties.

Recall that in the land of expression types
what we had in mind to make type checking reasonably efficient is to
first compare types for syntactic equality before reducing a redex.
A popular way to do this {\it with} grammatically enforced correctness
properties is to implement an environment machine evaluator. Therein
an expression evalutes to a WHNF value, where constructor heads
(like \texttt{Suc}) store an environment along with an unevaluated
expression. The environment only contains WHNF's for all free
variables in the expression, but not for binding positions (like the
\texttt{Lam} body or the \texttt{Pi} codomain).

\subsection{Independence}

\appendix
\section{Appendix Title}

This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}


\end{document}

